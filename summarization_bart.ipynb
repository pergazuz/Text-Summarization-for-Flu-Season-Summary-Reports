{"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/summarization.ipynb","timestamp":1712234297760}],"gpuType":"T4"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7a15c2f7316e4e068aab39a91c737620":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f283a04d78154568af131d2ecb46794b","IPY_MODEL_929b3c240c86477cada747b02375f1dc","IPY_MODEL_8d7107e4bacc42d09d2c1aa7bc8ffe10","IPY_MODEL_58f75e80b8c34c29b2099e2494770561","IPY_MODEL_fbdf28a426d14922ba67f7b3fd363b11"],"layout":"IPY_MODEL_96a3fd72f8804a43bd322cc1f32d52ab"}},"f283a04d78154568af131d2ecb46794b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0553cb622f6c47faae644c413a7111ff","placeholder":"​","style":"IPY_MODEL_2ce681fc22a948d2b4390a5ae6d2cd1e","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"929b3c240c86477cada747b02375f1dc":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4352358108934df6849beb8777273660","placeholder":"​","style":"IPY_MODEL_077b2837466a49dcb3beab2bbcdb941e","value":""}},"8d7107e4bacc42d09d2c1aa7bc8ffe10":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_eb09fe1957d54b169e73f1377d47b69c","style":"IPY_MODEL_85f8bf86c66f48438716c7491b21270a","value":true}},"58f75e80b8c34c29b2099e2494770561":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_22707151d12247b6b5d17212b040c6a1","style":"IPY_MODEL_ceb9ab464bed488f871fad8b58497d97","tooltip":""}},"fbdf28a426d14922ba67f7b3fd363b11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af38d3eec3cc453eaba16ed4e4aa3d3f","placeholder":"​","style":"IPY_MODEL_65d2344333084bbbb3fc473bc846402f","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"96a3fd72f8804a43bd322cc1f32d52ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"0553cb622f6c47faae644c413a7111ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ce681fc22a948d2b4390a5ae6d2cd1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4352358108934df6849beb8777273660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"077b2837466a49dcb3beab2bbcdb941e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb09fe1957d54b169e73f1377d47b69c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f8bf86c66f48438716c7491b21270a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22707151d12247b6b5d17212b040c6a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceb9ab464bed488f871fad8b58497d97":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"af38d3eec3cc453eaba16ed4e4aa3d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65d2344333084bbbb3fc473bc846402f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4afcce81ae40488a914b51cff1b35991":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0fff75c9bab4d5cad9f852570b69f70","IPY_MODEL_19dd914923d14e07bc90663caa6cbc39","IPY_MODEL_2c43b44b8fe5437d89d33c888779bb0c"],"layout":"IPY_MODEL_d3bc0730ff464fa589c95c56d614ce3d"}},"b0fff75c9bab4d5cad9f852570b69f70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5925408eab43558a49a61fc91e14e7","placeholder":"​","style":"IPY_MODEL_11da3d5ab1054784a3c76fb9004561f7","value":"Map: 100%"}},"19dd914923d14e07bc90663caa6cbc39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d156708150474b963ca68f5e5bcb97","max":989,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8175d7d04be24b03bbfa14685a877584","value":989}},"2c43b44b8fe5437d89d33c888779bb0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_115befe9b08f4d4aa301baa59eec15e7","placeholder":"​","style":"IPY_MODEL_dd7d35e9545a432ca78fe1264600bfe9","value":" 989/989 [00:13&lt;00:00, 75.38 examples/s]"}},"d3bc0730ff464fa589c95c56d614ce3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5925408eab43558a49a61fc91e14e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11da3d5ab1054784a3c76fb9004561f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d156708150474b963ca68f5e5bcb97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8175d7d04be24b03bbfa14685a877584":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"115befe9b08f4d4aa301baa59eec15e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7d35e9545a432ca78fe1264600bfe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cbb59d4c87f4aacbd18f3005d78c5ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47149f74f2e2455dbc935c1763e11328","IPY_MODEL_d96f0736b9804107ba48c997e1c9b5e9","IPY_MODEL_556fc7efb70b485cad80ec6a61c096ce"],"layout":"IPY_MODEL_0512d2246d8a44f99b6004496ea53136"}},"47149f74f2e2455dbc935c1763e11328":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c95b50b3394f1a9f180eadb2ebe4b4","placeholder":"​","style":"IPY_MODEL_9523e209f13741028f100c044bd79b0f","value":"Map: 100%"}},"d96f0736b9804107ba48c997e1c9b5e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d81a437fee746b1956ad4832e9c0fb6","max":248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9b851375c7e4cf8880b560d96a73f70","value":248}},"556fc7efb70b485cad80ec6a61c096ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84494e71bdde4903b2bd6633c5cc7c92","placeholder":"​","style":"IPY_MODEL_765a5785d59e46e79c3b4211bcd23b26","value":" 248/248 [00:02&lt;00:00, 89.23 examples/s]"}},"0512d2246d8a44f99b6004496ea53136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c95b50b3394f1a9f180eadb2ebe4b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9523e209f13741028f100c044bd79b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d81a437fee746b1956ad4832e9c0fb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b851375c7e4cf8880b560d96a73f70":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84494e71bdde4903b2bd6633c5cc7c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"765a5785d59e46e79c3b4211bcd23b26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8071353,"sourceType":"datasetVersion","datasetId":4762546},{"sourceId":8122115,"sourceType":"datasetVersion","datasetId":4799385},{"sourceId":8269833,"sourceType":"datasetVersion","datasetId":4909789}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Transformers installation\n! pip install transformers datasets\n# To install from source instead of the last release, comment the command above and uncomment the following one.\n# ! pip install git+https://github.com/huggingface/transformers.git","metadata":{"id":"gx5ZYXTzHNOQ","executionInfo":{"status":"ok","timestamp":1712513521111,"user_tz":-420,"elapsed":9934,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"53cd6ba4-ed02-4440-94a0-422fab5b18cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summarization","metadata":{"id":"Mgkx5XMeHNOR"}},{"cell_type":"markdown","source":"token: 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","metadata":{"id":"oM1D1-FRKS-R"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login, login\n\nlogin(token=\"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\")\nnotebook_login()","metadata":{"id":"cIHfpP7zHNOT","executionInfo":{"status":"ok","timestamp":1712513521675,"user_tz":-420,"elapsed":567,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"32f4628d-fd69-4318-8a8a-e3c4353817f7","execution":{"iopub.status.busy":"2024-04-30T08:37:44.646955Z","iopub.execute_input":"2024-04-30T08:37:44.647660Z","iopub.status.idle":"2024-04-30T08:37:45.105144Z","shell.execute_reply.started":"2024-04-30T08:37:44.647621Z","shell.execute_reply":"2024-04-30T08:37:45.103889Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769149a10ceb4cd18b52ebf5506d3dca"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Load dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\nflu = pd.read_csv(\"/kaggle/input/bart-summary/flu_data_summary_abstractive.csv\")\nflu = flu.dropna()\nflu","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:37:53.267341Z","iopub.execute_input":"2024-04-30T08:37:53.267741Z","iopub.status.idle":"2024-04-30T08:37:54.187451Z","shell.execute_reply.started":"2024-04-30T08:37:53.267705Z","shell.execute_reply":"2024-04-30T08:37:54.186431Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          Year                                              Topic  \\\n1    2006-2007           How severe was the 2006-2007 flu season?   \n5    2006-2007  How many people died from flu during the 2006-...   \n7    2006-2007  Was there a good match between the influenza s...   \n9    2006-2007  What can be done to protect children from flu-...   \n16   2007-2008           What flu viruses circulated this season?   \n..         ...                                                ...   \n134  2021-2022  What vaccine uptake estimates did CDC provide ...   \n135  2021-2022  Were there any updates in the methods for flu ...   \n137  2023-2024  Updates to U.S. Flu Surveillance Methods for t...   \n138  2023-2024                B/Yamagata and Flu Vaccines Summary   \n140  2023-2024  Flu, RSV, and COVID-19 Coinfection Data: 2023-...   \n\n                                               Content  \\\n1    The 2006-07 flu season was generally mild comp...   \n5    Exact numbers of how many people died from flu...   \n7    The influenza A (H1) component of the 2006-07 ...   \n9    Vaccination remains the best method for preven...   \n16   In the United States, influenza A (H1N1), A (H...   \n..                                                 ...   \n134  CDC’s Weekly Flu Vaccination Dashboard provide...   \n135  During the 2021-2022 flu season, there were a ...   \n137  Starting with the 2023-2024 influenza season, ...   \n138  Quadrivalent flu vaccines protect against four...   \n140  One way CDC collects data on coinfections with...   \n\n                                               LexRank  \\\n1    Flu activity increased during late December, p...   \n5    Estimates of flu-associated deaths are made by...   \n7    Overall for the 2006-07 season, 24 percent of ...   \n9    Children with asthma or other conditions shoul...   \n16   Flu A viruses are subtyped in public health la...   \n..                                                 ...   \n134  Additional information about NIS-Flu methods a...   \n135  More information on flu surveillance methodolo...   \n137  Flu vaccination is often available at no or lo...   \n138  CDC is not involved in regulatory decision-mak...   \n140  It also shows the percentages of flu and COVID...   \n\n                                              TextRank  \\\n1    For example, the proportion of all deaths asso...   \n5    Estimates of flu-associated deaths are made by...   \n7    In the early months of the season, the majorit...   \n9    Household contacts and caregivers of these chi...   \n16   Influenza A viruses accounted for 71% of the s...   \n..                                                 ...   \n134  CDC’s Weekly Flu Vaccination Dashboard provide...   \n135  Hospitals in all 50 states and U.S. territorie...   \n137  Flu vaccination is often available at no or lo...   \n138  Quadrivalent flu vaccines protect against four...   \n140  The table provides the total number of COVID-1...   \n\n                                               Pegasus  \\\n1    For example, the proportion of all deaths asso...   \n5    This system collects information each week on ...   \n7    Fifty percent of the influenza B viruses chara...   \n9    Household contacts and caregivers of these chi...   \n16   Influenza A viruses accounted for 71% of the s...   \n..                                                 ...   \n134  The dashboard included information on the numb...   \n135  CDC also added a surveillance system that trac...   \n137  Although monitoring influenza-only coded death...   \n138  Quadrivalent flu vaccines protect against four...   \n140  The table provides the total number of COVID-1...   \n\n                                                  Bart  \n1    The 2006-07 flu season was generally mild comp...  \n5    Flu-associated deaths are only a nationally no...  \n7    The influenza A (H1) component of the 2006-07 ...  \n9    Vaccination remains the best method for preven...  \n16    Influenza A viruses accounted for 71% of the ...  \n..                                                 ...  \n134  CDC’s Weekly Flu Vaccination Dashboard provide...  \n135  CDC added another surveillance system, the HHS...  \n137  Starting with the 2023-2024 influenza season, ...  \n138  All current flu vaccines in the United States ...  \n140  CDC collects data on coinfections with influen...  \n\n[70 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Topic</th>\n      <th>Content</th>\n      <th>LexRank</th>\n      <th>TextRank</th>\n      <th>Pegasus</th>\n      <th>Bart</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2006-2007</td>\n      <td>How severe was the 2006-2007 flu season?</td>\n      <td>The 2006-07 flu season was generally mild comp...</td>\n      <td>Flu activity increased during late December, p...</td>\n      <td>For example, the proportion of all deaths asso...</td>\n      <td>For example, the proportion of all deaths asso...</td>\n      <td>The 2006-07 flu season was generally mild comp...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2006-2007</td>\n      <td>How many people died from flu during the 2006-...</td>\n      <td>Exact numbers of how many people died from flu...</td>\n      <td>Estimates of flu-associated deaths are made by...</td>\n      <td>Estimates of flu-associated deaths are made by...</td>\n      <td>This system collects information each week on ...</td>\n      <td>Flu-associated deaths are only a nationally no...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2006-2007</td>\n      <td>Was there a good match between the influenza s...</td>\n      <td>The influenza A (H1) component of the 2006-07 ...</td>\n      <td>Overall for the 2006-07 season, 24 percent of ...</td>\n      <td>In the early months of the season, the majorit...</td>\n      <td>Fifty percent of the influenza B viruses chara...</td>\n      <td>The influenza A (H1) component of the 2006-07 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2006-2007</td>\n      <td>What can be done to protect children from flu-...</td>\n      <td>Vaccination remains the best method for preven...</td>\n      <td>Children with asthma or other conditions shoul...</td>\n      <td>Household contacts and caregivers of these chi...</td>\n      <td>Household contacts and caregivers of these chi...</td>\n      <td>Vaccination remains the best method for preven...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2007-2008</td>\n      <td>What flu viruses circulated this season?</td>\n      <td>In the United States, influenza A (H1N1), A (H...</td>\n      <td>Flu A viruses are subtyped in public health la...</td>\n      <td>Influenza A viruses accounted for 71% of the s...</td>\n      <td>Influenza A viruses accounted for 71% of the s...</td>\n      <td>Influenza A viruses accounted for 71% of the ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>2021-2022</td>\n      <td>What vaccine uptake estimates did CDC provide ...</td>\n      <td>CDC’s Weekly Flu Vaccination Dashboard provide...</td>\n      <td>Additional information about NIS-Flu methods a...</td>\n      <td>CDC’s Weekly Flu Vaccination Dashboard provide...</td>\n      <td>The dashboard included information on the numb...</td>\n      <td>CDC’s Weekly Flu Vaccination Dashboard provide...</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>2021-2022</td>\n      <td>Were there any updates in the methods for flu ...</td>\n      <td>During the 2021-2022 flu season, there were a ...</td>\n      <td>More information on flu surveillance methodolo...</td>\n      <td>Hospitals in all 50 states and U.S. territorie...</td>\n      <td>CDC also added a surveillance system that trac...</td>\n      <td>CDC added another surveillance system, the HHS...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>2023-2024</td>\n      <td>Updates to U.S. Flu Surveillance Methods for t...</td>\n      <td>Starting with the 2023-2024 influenza season, ...</td>\n      <td>Flu vaccination is often available at no or lo...</td>\n      <td>Flu vaccination is often available at no or lo...</td>\n      <td>Although monitoring influenza-only coded death...</td>\n      <td>Starting with the 2023-2024 influenza season, ...</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>2023-2024</td>\n      <td>B/Yamagata and Flu Vaccines Summary</td>\n      <td>Quadrivalent flu vaccines protect against four...</td>\n      <td>CDC is not involved in regulatory decision-mak...</td>\n      <td>Quadrivalent flu vaccines protect against four...</td>\n      <td>Quadrivalent flu vaccines protect against four...</td>\n      <td>All current flu vaccines in the United States ...</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>2023-2024</td>\n      <td>Flu, RSV, and COVID-19 Coinfection Data: 2023-...</td>\n      <td>One way CDC collects data on coinfections with...</td>\n      <td>It also shows the percentages of flu and COVID...</td>\n      <td>The table provides the total number of COVID-1...</td>\n      <td>The table provides the total number of COVID-1...</td>\n      <td>CDC collects data on coinfections with influen...</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"flu = flu[0:100]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:37:55.013658Z","iopub.execute_input":"2024-04-30T08:37:55.014064Z","iopub.status.idle":"2024-04-30T08:37:55.019412Z","shell.execute_reply.started":"2024-04-30T08:37:55.014027Z","shell.execute_reply":"2024-04-30T08:37:55.018201Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"flu_dataset = Dataset.from_pandas(flu)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:37:55.831829Z","iopub.execute_input":"2024-04-30T08:37:55.832795Z","iopub.status.idle":"2024-04-30T08:37:55.856221Z","shell.execute_reply.started":"2024-04-30T08:37:55.832756Z","shell.execute_reply":"2024-04-30T08:37:55.855192Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Sample data for training","metadata":{}},{"cell_type":"code","source":"flu_dataset['Content'][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:37:58.105616Z","iopub.execute_input":"2024-04-30T08:37:58.106063Z","iopub.status.idle":"2024-04-30T08:37:58.113817Z","shell.execute_reply.started":"2024-04-30T08:37:58.106028Z","shell.execute_reply":"2024-04-30T08:37:58.112827Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'The 2006-07 flu season was generally mild compared to recent flu seasons. For example, the proportion of all deaths associated with influenza illness was lower this season than the previous three flu seasons. Hospitalization rates among children were also lower than the previous three flu seasons. However, more pediatric deaths related to influenza were reported during the 2006-07 season than the previous two seasons. Nationally, low levels of flu activity were reported during October through mid-December. Flu activity increased during late December, peaked in mid-February, and decreased through the end of the flu season on May 19.'"},"metadata":{}}]},{"cell_type":"markdown","source":"Split the dataset into a train and test set with the [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) method:","metadata":{"id":"qFR0QqFDHNOU"}},{"cell_type":"code","source":"flu_dataset = flu_dataset.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:38:00.616486Z","iopub.execute_input":"2024-04-30T08:38:00.617458Z","iopub.status.idle":"2024-04-30T08:38:00.631342Z","shell.execute_reply.started":"2024-04-30T08:38:00.617407Z","shell.execute_reply":"2024-04-30T08:38:00.630321Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"flu_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:38:00.929372Z","iopub.execute_input":"2024-04-30T08:38:00.930440Z","iopub.status.idle":"2024-04-30T08:38:00.936748Z","shell.execute_reply.started":"2024-04-30T08:38:00.930400Z","shell.execute_reply":"2024-04-30T08:38:00.935698Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Year', 'Topic', 'Content', 'LexRank', 'TextRank', 'Pegasus', 'Bart', '__index_level_0__'],\n        num_rows: 56\n    })\n    test: Dataset({\n        features: ['Year', 'Topic', 'Content', 'LexRank', 'TextRank', 'Pegasus', 'Bart', '__index_level_0__'],\n        num_rows: 14\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Then take a look at an example:","metadata":{"id":"9fI_8p_tHNOU"}},{"cell_type":"markdown","source":"There are two fields that you'll want to use:\n\n- `Content`: the text of the bill which'll be the input to the model.\n- `Summary`: a condensed version of `Content` which'll be the model target.","metadata":{"id":"9VUHh5NDHNOV"}},{"cell_type":"markdown","source":"## Preprocess","metadata":{"id":"S1325FHsHNOV"}},{"cell_type":"markdown","source":"The next step is to load a T5 tokenizer to process `text` and `summary`:","metadata":{"id":"8B2m1fL7HNOV"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"facebook/bart-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"id":"htUmG4zJHNOV","executionInfo":{"status":"ok","timestamp":1712513529733,"user_tz":-420,"elapsed":3336,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:38:03.589573Z","iopub.execute_input":"2024-04-30T08:38:03.589972Z","iopub.status.idle":"2024-04-30T08:38:06.694034Z","shell.execute_reply.started":"2024-04-30T08:38:03.589938Z","shell.execute_reply":"2024-04-30T08:38:06.693141Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"The preprocessing function you want to create needs to:\n\n1. Prefix the input with a prompt so T5 knows this is a summarization task. Some models capable of multiple NLP tasks require prompting for specific tasks.\n2. Use the keyword `text_target` argument when tokenizing labels.\n3. Truncate sequences to be no longer than the maximum length set by the `max_length` parameter.","metadata":{"id":"ev9puw-IHNOV"}},{"cell_type":"code","source":"prefix = \"summarize: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"Content\"]]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    labels = tokenizer(text_target=examples[\"Bart\"], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:38:06.695727Z","iopub.execute_input":"2024-04-30T08:38:06.696187Z","iopub.status.idle":"2024-04-30T08:38:06.702979Z","shell.execute_reply.started":"2024-04-30T08:38:06.696159Z","shell.execute_reply":"2024-04-30T08:38:06.701839Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"To apply the preprocessing function over the entire dataset, use 🤗 Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) method. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once:","metadata":{"id":"fj-jPabbHNOV"}},{"cell_type":"code","source":"tokenized_flu = flu_dataset.map(preprocess_function, batched=True)","metadata":{"id":"2kJ5XuQYHNOV","executionInfo":{"status":"ok","timestamp":1712513545758,"user_tz":-420,"elapsed":16029,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"c24ccc23-0464-4392-cab3-1f5313fb80e1","execution":{"iopub.status.busy":"2024-04-30T08:38:08.598737Z","iopub.execute_input":"2024-04-30T08:38:08.599662Z","iopub.status.idle":"2024-04-30T08:38:08.962047Z","shell.execute_reply.started":"2024-04-30T08:38:08.599617Z","shell.execute_reply":"2024-04-30T08:38:08.960935Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014eecd027b647a695edb419045ded88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fd48446dfa4add90b585381a959988"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_flu","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:38:09.042667Z","iopub.execute_input":"2024-04-30T08:38:09.043053Z","iopub.status.idle":"2024-04-30T08:38:09.049886Z","shell.execute_reply.started":"2024-04-30T08:38:09.043022Z","shell.execute_reply":"2024-04-30T08:38:09.048790Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Year', 'Topic', 'Content', 'LexRank', 'TextRank', 'Pegasus', 'Bart', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 56\n    })\n    test: Dataset({\n        features: ['Year', 'Topic', 'Content', 'LexRank', 'TextRank', 'Pegasus', 'Bart', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 14\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Now create a batch of examples using [DataCollatorForSeq2Seq](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForSeq2Seq). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.","metadata":{"id":"zXrX_uYWHNOV"}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"id":"niB_zfd2HNOV","executionInfo":{"status":"ok","timestamp":1712513551578,"user_tz":-420,"elapsed":5823,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:38:11.473594Z","iopub.execute_input":"2024-04-30T08:38:11.474366Z","iopub.status.idle":"2024-04-30T08:38:14.769385Z","shell.execute_reply.started":"2024-04-30T08:38:11.474333Z","shell.execute_reply":"2024-04-30T08:38:14.768422Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-04-30 08:38:12.445456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-30 08:38:12.445517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-30 08:38:12.447160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate","metadata":{"id":"LsP2-EdzHNOV"}},{"cell_type":"markdown","source":"Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [ROUGE](https://huggingface.co/spaces/evaluate-metric/rouge) metric (see the 🤗 Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):","metadata":{"id":"KZN4Nf-RHNOV"}},{"cell_type":"code","source":"!pip install evaluate\n!pip install rouge_score\n# !pip install transformers[torch]\n# !pip install accelerate -U","metadata":{"id":"m0XS7E5xK9zG","executionInfo":{"status":"ok","timestamp":1712513569860,"user_tz":-420,"elapsed":18285,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"ce3bf501-d29c-446c-cec3-4a88059850af","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"id":"f30hePjbHNOW","executionInfo":{"status":"ok","timestamp":1712513572145,"user_tz":-420,"elapsed":2291,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:38:14.771009Z","iopub.execute_input":"2024-04-30T08:38:14.771634Z","iopub.status.idle":"2024-04-30T08:38:16.086749Z","shell.execute_reply.started":"2024-04-30T08:38:14.771601Z","shell.execute_reply":"2024-04-30T08:38:16.085772Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the ROUGE metric:","metadata":{"id":"y1lZepgVHNOW"}},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"id":"puQXZ0HQHNOW","executionInfo":{"status":"ok","timestamp":1712513572145,"user_tz":-420,"elapsed":4,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:38:17.677687Z","iopub.execute_input":"2024-04-30T08:38:17.678793Z","iopub.status.idle":"2024-04-30T08:38:17.686455Z","shell.execute_reply.started":"2024-04-30T08:38:17.678754Z","shell.execute_reply":"2024-04-30T08:38:17.685159Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training.","metadata":{"id":"Bxvw5-X4HNOW"}},{"cell_type":"markdown","source":"## Train","metadata":{"id":"y8TBVfwWHNOW"}},{"cell_type":"markdown","source":"<Tip>\n\nIf you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n\n</Tip>\n\nYou're ready to start training your model now! Load T5 with [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM):","metadata":{"id":"NAq8fgPaHNOW"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModel\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"id":"3GQL9viAHNOW","executionInfo":{"status":"ok","timestamp":1712513573123,"user_tz":-420,"elapsed":981,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:38:19.695126Z","iopub.execute_input":"2024-04-30T08:38:19.695521Z","iopub.status.idle":"2024-04-30T08:38:20.963148Z","shell.execute_reply.started":"2024-04-30T08:38:19.695482Z","shell.execute_reply":"2024-04-30T08:38:20.961977Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"At this point, only three steps remain:\n\n1. Define your training hyperparameters in [Seq2SeqTrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the ROUGE metric and save the training checkpoint.\n2. Pass the training arguments to [Seq2SeqTrainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model.","metadata":{"id":"uJtrkGnJHNOW"}},{"cell_type":"code","source":"!pip install accelerate -U\n!pip install transformers[torch]","metadata":{"id":"FPw-jlAGwO6_","executionInfo":{"status":"ok","timestamp":1712514026502,"user_tz":-420,"elapsed":17209,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"40a36e3f-9c49-4551-af88-46bdb3270281","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"cdc_influenza_bart-base-cnn\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=4,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_flu[\"train\"],\n    eval_dataset=tokenized_flu[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"id":"tPHDwPZAHNOW","executionInfo":{"status":"error","timestamp":1712514053350,"user_tz":-420,"elapsed":5,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"outputId":"bf545ca0-75b3-49cd-b5b7-69c46d2a6f67","execution":{"iopub.status.busy":"2024-04-30T08:38:22.291332Z","iopub.execute_input":"2024-04-30T08:38:22.292344Z","iopub.status.idle":"2024-04-30T08:39:12.528575Z","shell.execute_reply.started":"2024-04-30T08:38:22.292304Z","shell.execute_reply":"2024-04-30T08:39:12.527158Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpanupongtongfah\u001b[0m (\u001b[33mpergazuz\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240430_083825-cttaxlfg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pergazuz/huggingface/runs/cttaxlfg/workspace' target=\"_blank\">fresh-silence-43</a></strong> to <a href='https://wandb.ai/pergazuz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pergazuz/huggingface' target=\"_blank\">https://wandb.ai/pergazuz/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pergazuz/huggingface/runs/cttaxlfg/workspace' target=\"_blank\">https://wandb.ai/pergazuz/huggingface/runs/cttaxlfg/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8/8 00:23, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.811992</td>\n      <td>0.308000</td>\n      <td>0.227200</td>\n      <td>0.272300</td>\n      <td>0.275800</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.642664</td>\n      <td>0.347300</td>\n      <td>0.263500</td>\n      <td>0.317900</td>\n      <td>0.318900</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.549590</td>\n      <td>0.392500</td>\n      <td>0.320300</td>\n      <td>0.367100</td>\n      <td>0.364200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.515455</td>\n      <td>0.382900</td>\n      <td>0.308600</td>\n      <td>0.362300</td>\n      <td>0.357600</td>\n      <td>20.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8, training_loss=0.9634270071983337, metrics={'train_runtime': 48.7908, 'train_samples_per_second': 4.591, 'train_steps_per_second': 0.164, 'total_flos': 136580966645760.0, 'train_loss': 0.9634270071983337, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:","metadata":{"id":"pPUwxbYLHNOW"}},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"id":"zZEylIvJHNOW","executionInfo":{"status":"aborted","timestamp":1712513373344,"user_tz":-420,"elapsed":491,"user":{"displayName":"panupong tf","userId":"16762196326173702680"}},"execution":{"iopub.status.busy":"2024-04-30T08:39:34.949606Z","iopub.execute_input":"2024-04-30T08:39:34.950043Z","iopub.status.idle":"2024-04-30T08:39:51.611672Z","shell.execute_reply.started":"2024-04-30T08:39:34.949992Z","shell.execute_reply":"2024-04-30T08:39:51.610406Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcb2ca90a0cb4cc38f04a265180fb9de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36a31fc0f674acabbcfc6c1baf7f396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714466303.647ab1a00d71.2209.0:   0%|          | 0.00/8.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acae4f3fea17436e9220983c7803a02c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1714466087.647ab1a00d71.2068.0:   0%|          | 0.00/8.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b340a63dcd64832bfb81e187c1721f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eef66be593e4810b1af1fb5117ea28f"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/PergaZuZ/cdc_influenza_bart-base-cnn/commit/b9359ed6d6a8eef7aeb5ebf692fd25487d6789ab', commit_message='End of training', commit_description='', oid='b9359ed6d6a8eef7aeb5ebf692fd25487d6789ab', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"<Tip>\n\nFor a more in-depth example of how to finetune a model for summarization, take a look at the corresponding\n[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)\nor [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb).\n\n</Tip>","metadata":{"id":"loT64htpHNOW"}},{"cell_type":"markdown","source":"## Inference","metadata":{"id":"5pHEj_79HNOW"}},{"cell_type":"markdown","source":"Great, now that you've finetuned a model, you can use it for inference!\n\nCome up with some text you'd like to summarize. For T5, you need to prefix your input depending on the task you're working on. For summarization you should prefix your input as shown below:","metadata":{"id":"Xj2-SFTVHNOW"}},{"cell_type":"code","source":"text = \"summarize: The 2006-07 flu season was generally mild compared to recent flu seasons. For example, the proportion of all deaths associated with influenza illness was lower this season than the previous three flu seasons. Hospitalization rates among children were also lower than the previous three flu seasons. However, more pediatric deaths related to influenza were reported during the 2006-07 season than the previous two seasons. Nationally, low levels of flu activity were reported during October through mid-December. Flu activity increased during late December, peaked in mid-February, and decreased through the end of the flu season on May 19.\"","metadata":{"id":"JyungZnRHNOX","execution":{"iopub.status.busy":"2024-04-30T08:39:55.585339Z","iopub.execute_input":"2024-04-30T08:39:55.586530Z","iopub.status.idle":"2024-04-30T08:39:55.593464Z","shell.execute_reply.started":"2024-04-30T08:39:55.586490Z","shell.execute_reply":"2024-04-30T08:39:55.592180Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for summarization with your model, and pass your text to it:","metadata":{"id":"fZMx7LhOHNOc"}},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"PergaZuZ/cdc_influenza_bart-base-cnn\", max_length=70)\nsummarizer(text)","metadata":{"id":"WbX5rzfhHNOc","outputId":"b103bc48-3a05-488a-8ed1-470326912ab4","execution":{"iopub.status.busy":"2024-04-30T08:39:57.839605Z","iopub.execute_input":"2024-04-30T08:39:57.840446Z","iopub.status.idle":"2024-04-30T08:40:07.952110Z","shell.execute_reply.started":"2024-04-30T08:39:57.840408Z","shell.execute_reply":"2024-04-30T08:40:07.951024Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"535176f7f3e34db99f62b0498182f6ba"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': 'Flu activity was generally mild compared to recent flu seasons. Flu activity increased during late December, peaked in mid-February, and decreased through the end of the flu season on May 19.'}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", max_length=70)\nsummarizer(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T08:40:10.330406Z","iopub.execute_input":"2024-04-30T08:40:10.330952Z","iopub.status.idle":"2024-04-30T08:40:19.717516Z","shell.execute_reply.started":"2024-04-30T08:40:10.330913Z","shell.execute_reply":"2024-04-30T08:40:19.716406Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': 'The 2006-07 flu season was generally mild compared to recent flu seasons. Nationally, low levels of flu activity were reported during October through mid-December. Flu activity increased during late December, peaked in mid-February, and decreased through the end of the flu season on May 19.'}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"PergaZuZ/cdc_influenza_pagasus-x-large\", max_length=70)\nsummarizer(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"google/pegasus-large\", max_length=70)\nsummarizer(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", max_length=70)\nsummarizer(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"PergaZuZ/cdc_influenza_bart_large_cnn\", max_length=70)\nsummarizer(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can also manually replicate the results of the `pipeline` if you'd like:\n\n\nTokenize the text and return the `input_ids` as PyTorch tensors:","metadata":{"id":"yoDIaMTQHNOc"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"PergaZuZ/cdc_influenza\")\ninputs = tokenizer(text, return_tensors=\"pt\").input_ids","metadata":{"id":"vf-iO-whHNOc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the [generate()](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate) method to create the summarization. For more details about the different text generation strategies and parameters for controlling generation, check out the [Text Generation](https://huggingface.co/docs/transformers/main/en/tasks/../main_classes/text_generation) API.","metadata":{"id":"fHTLuvj9HNOc"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"PergaZuZ/cdc_influenza\")\noutputs = model.generate(inputs, max_new_tokens=100, do_sample=False)","metadata":{"id":"ZkOwSLF-HNOc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decode the generated token ids back into text:","metadata":{"id":"J8sDUVPYHNOc"}},{"cell_type":"code","source":"tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"id":"v8S_LSJoHNOc","outputId":"355caf74-34b6-45d5-8cf3-fdf5f6fb1df9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}